{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true,
                "tags": [
                    "hide-input"
                ]
            },
            "outputs": [],
            "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nfrom sklearn import preprocessing\nfrom scipy import stats\nimport scipy as sp\nimport random\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score,f1_score,log_loss,classification_report,confusion_matrix\n# from sklearn.metrics import jaccard_similarity_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import svm\nfrom sklearn import metrics\nimport matplotlib.image as mpimg\nfrom io import StringIO\nimport itertools\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\n!pip install folium\nimport webbrowser\nfrom folium import plugins\n!pip install imblearn\nfrom imblearn.over_sampling import SMOTE\n%matplotlib inline"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": [
                    "hide-input"
                ]
            },
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "main_df = pd.read_csv(body)\n#main_df.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "main_df.describe()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Understanding the descriptive statistics\n\ndescriptive_stats= main_df.describe(include='all')\n\ndescriptive_stats_plot=descriptive_stats[[\"INATTENTIONIND\",\"UNDERINFL\",\"WEATHER\",\"ROADCOND\",\"LIGHTCOND\",\"SPEEDING\",\"SEVERITYCODE\"]]\ndescriptive_stats_plot.drop(['unique','top','freq','mean','std','min','max','25%','50%','75%'],axis=0,inplace=True)\ndescriptive_stats_plot=descriptive_stats_plot.transpose()\n\ncolor_yo=['skyblue','red','red','red','red','skyblue','red']\ndescriptive_stats_plot.plot(kind='bar',alpha=0.70,color=[color_yo],legend=None)\nplt.title('Number of entries for each Dataset Feature', fontsize=20)\nplt.xlabel(\"Variables\",fontsize=15,labelpad=20)\nplt.ylabel(\"Frequency\",fontsize=15,labelpad=20)\nplt.xticks(rotation=270)\nplt.show()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "explode_list = [0.05, 0.05, 0.2]\ncolor_list=['peachpuff','orange','darkorange']\naddrtype=main_df['ADDRTYPE'].value_counts()\n\naddrtype.plot(kind='pie',\n            figsize=(15, 6),\n            autopct='%1.1f%%',\n            startangle=90,\n            shadow=True,\n            labels=None,\n            labeldistance=1.15,\n            colors=color_list,\n            explode=explode_list)\n\nplt.title('Accident Enivironment', fontsize=18)\nplt.axis('scaled')\nplt.legend(labels=addtype.index, loc='lower left')\n\nplt.show()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#\nmain_df['INCKEY'].nunique()\n\n\nmain_df[\"INATTENTIONIND\"].replace(\"Y\", 1, inplace=True)\nmain_df[\"INATTENTIONIND\"].replace(np.nan, 0, inplace=True)\n\n\nmain_df[\"UNDERINFL\"].replace(\"N\", 0, inplace=True)\nmain_df[\"UNDERINFL\"].replace(\"Y\", 1, inplace=True)\nmain_df[\"UNDERINFL\"].replace()\n\n\nmain_df[\"SPEEDING\"].replace(\"Y\", 1, inplace=True)\nmain_df[\"SPEEDING\"].replace(np.nan, 0, inplace=True)\n\n# Replacements are in 3 seperate categories, Day, Night-lit, and Night-unlit\n\nmain_df[\"LIGHTCOND\"].replace(\"Daylight\", 0, inplace=True)\nmain_df[\"LIGHTCOND\"].replace([\"Dark - Street Lights On\",\"Dusk\",\"Dawn\"], 1, inplace=True)\nmain_df[\"LIGHTCOND\"].replace([\"Dark - No Street Lights\",\"Dark - Street Lights Off\",\"Dark - Unknown Lighting\"], 2, inplace=True)\nmain_df[\"LIGHTCOND\"].replace([\"Other\"],\"Unknown\", inplace=True)\n\n# Replacements are in 4 seperate categories, Clear, Cloudy, Wind-related, and Raining\n\nmain_df[\"WEATHER\"].replace(\"Clear\", 0, inplace=True)\nmain_df[\"WEATHER\"].replace([\"Overcast\",\"Partly Cloudy\"], 1, inplace=True)\nmain_df[\"WEATHER\"].replace([\"Fog/Smog/Smoke\",\"Blowing Sand/Dirt\",\"Severe Crosswind\"], 2, inplace=True)\nmain_df[\"WEATHER\"].replace([\"Sleet/Hail/Freezing Rain\",\"Snowing\",\"Raining\"], 3, inplace=True)\nmain_df[\"WEATHER\"].replace(\"Other\", \"Unknown\", inplace=True)\n\n# Replacements are in 3 seperate categories, Dry, Bumpy, Wet/Slippery\n\nmain_df[\"ROADCOND\"].replace(\"Dry\", 0, inplace=True)\nmain_df[\"ROADCOND\"].replace([\"Snow/Slush\",\"Sand/Mud/Dirt\"], 1, inplace=True)\nmain_df[\"ROADCOND\"].replace([\"Wet\",\"Ice\",\"Standing Water\",\"Oil\"], 2, inplace=True)\nmain_df[\"ROADCOND\"].replace([\"Other\",\"NAN\"], \"Unknown\", inplace=True)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "selected_columns=main_df[[\"X\",\"Y\",\"INCKEY\",\"INATTENTIONIND\",\"UNDERINFL\",\"WEATHER\",\"ROADCOND\",\"LIGHTCOND\",\"SPEEDING\",\"SEVERITYCODE\"]]\nfeature_df=selected_columns.copy()\nfeature_df.dropna(axis=1,how='all',inplace=True)\nfeature_stats=feature_df.describe()\nfeature_stats"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "np.count_nonzero(feature_df['UNDERINFL'])"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "feature_df[\"SPEEDING\"]=feature_df[\"SPEEDING\"].astype(int)\nfeature_df[\"INATTENTIONIND\"]=feature_df[\"INATTENTIONIND\"].astype(int)\nfeature_df[\"UNDERINFL\"]=feature_df[\"UNDERINFL\"].astype(int)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "lightcondsize = feature_df [\"LIGHTCOND\"].size\n\nfeature_df[\"LIGHTCOND\"].fillna(3,inplace=True)\n\nfeatureinlightcond = feature_df ['LIGHTCOND'] == 'Unknown'\n\nlightcond = feature_df['LIGHTCOND']\nlightcond = lightcond.values\nlightcond = lightcond[featureinlightcond]\n\nlightcond[0:9036]=0\nlightcond[9036:13417]=1\nlightcond[13417:13961]=2\n\nfeature_df.loc [feature_df.LIGHTCOND == \"Unknown\", 'LIGHTCOND'] = lightcond\n\nfeature_df[\"LIGHTCOND\"]=feature_df[\"LIGHTCOND\"].astype(int)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "feature_df[\"LIGHTCOND\"].value_counts()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "roadcondsize = feature_df [\"ROADCOND\"].size\n\nfeatureinroadcond = feature_df ['ROADCOND'] == 'Unknown'\n\nfeature_df['ROADCOND'].fillna(0,inplace=True)\n\nroadcond = feature_df['LIGHTCOND']\nroadcond = roadcond.values\nroadcond = roadcond[featureinroadcond]\n\nroadcond[0:9954]=0\nroadcond[9954:10040]=1\nroadcond[10040:15163]=2\n\nfeature_df.loc[feature_df.ROADCOND == \"Unknown\", 'ROADCOND'] = roadcond\nfeature_df[\"ROADCOND\"]=feature_df[\"ROADCOND\"].astype(int)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "weathersize = feature_df [\"WEATHER\"].size\n\nfeatureinweather = feature_df ['WEATHER'] == 'Unknown'\n\nfeature_df['WEATHER'].fillna(0,inplace=True)\n\nweather = feature_df['WEATHER']\nweather = weather.values\nweather = weather[featureinweather]\n\nweather[0:10151]=0\nweather[10151:12683]=1\nweather[12683:12742]=2\nweather[12742:15864]=3\n\nfeature_df.loc[feature_df.WEATHER == \"Unknown\", 'WEATHER'] = weather\nfeature_df[\"WEATHER\"]=feature_df[\"WEATHER\"].astype(int)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "#Converting Severity Code from (1/2) to (0/1)\nseverity_code = main_df['SEVERITYCODE'].values\n\nheaders = preprocessing.LabelEncoder()\nheaders.fit([0, 1])\nseverity_code = headers.transform (severity_code)\n\nmain_df [\"SEVERITYCODE\"] = severity_code"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "X=feature_df[[\"SPEEDING\",\"INATTENTIONIND\",\"UNDERINFL\",\"ROADCOND\",\"WEATHER\",\"LIGHTCOND\"]].values\ny=feature_df[[\"SEVERITYCODE\"]].values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "ic = SMOTE (random_state=0)\nic_data_X, ic_data_y= ic.fit_sample(X_train, y_train)\n\nsmall_df = feature_df.iloc [0:100005:5, 0:]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Now it is time to load in the folium map of Seattle with a mark cluster object for the accidents\n\nseattle_map = folium.Map(location=[47.61536892, -122.3302243], zoom_start=10)\naccidents = plugins.MarkerCluster().add_to(seattle_map)\n\nfor lat, lng, label, in zip(small_df.Y, small_df.X, small_df.SEVERITYCODE):\n    folium.Marker(\n    location=[lat, lng],\n    icon=None,\n    popup=label,\n    ).add_to(accidents)\n\nseattle_map.add_child(accidents)\n\nseattle_map\nseattle_map.save(\"seattlemap.html\")\nwebbrowser.open(\"seattlemap.html\")"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Confusion Matrix set up for all analysis (took the longest time for the project)\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n    \nplt.imshow(cm, interpolation='nearest', cmap=cmap)\nplt.title(title)\nplt.colorbar()\ntick_marks = np.arange(len(classes))\nplt.xticks(tick_marks, classes, rotation=45)\nplt.yticks(tick_marks, classes)\n\nfmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "cnf_matrix = confusion_matrix(y_test, yhatDT, labels=[1,0])\nnp.set_printoptions(precision=2)\n\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['Injury=1','Property Damage=0'],normalize= False,  title='Confusion matrix')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Ks = 10\nmean_acc = np.zeros((Ks-1))\nstd_acc = np.zeros((Ks-1))\nConfustionMx = [];\nfor n in range(1,Ks):\n     \n    neigh = KNeighborsClassifier(n_neighbors = n).fit(ic_data_X,ic_data_y)\n    yhat=neigh.predict(X_test)\n    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n\n    \n    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n\nmean_acc"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "plt.plot(range(1,Ks),mean_acc,'g')\nplt.legend(('Accuracy ', '+/- 3xstd'))\nplt.ylabel('Accuracy ')\nplt.xlabel('Number of Neighbors (K)')\nplt.tight_layout()\nplt.show()\n\nprint( \"The best accuracy was with\", mean_acc.max(), \"with k=\", mean_acc.argmax()+1)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Logisitic regression\n\nLR = LogisticRegression(C=0.01, solver='liblinear').fit(ic_data_X,ic_data_y)\n\nyhatLR = LR.predict(X_test)\nyhat_prob = LR.predict_proba(X_test)\n\nprint(log_loss(y_test, yhat_prob))\n\nprint (\"Accuracy: \", accuracy_score(yhatLR,y_test))\nprint (classification_report(y_test, yhatLR))\n\ncnf_matrix = confusion_matrix(y_test, yhatLR, labels=[1,0])\nnp.set_printoptions(precision=2)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "plt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['Injury=1','Property Damage=0'],normalize= False,  title='Confusion matrix')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "DT = DecisionTreeClassifier(criterion=\"entropy\", max_depth=6)\nDT.fit(ic_data_X,ic_data_y)\n\nyhatDT = DT.predict(X_test)\n\nprint('Decision Tree Accuracy = ', accuracy_score(yhatDT, y_test))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Printing the confusion matrix visualizes the Accuracy of the Decision Tree\n\nprint('Confusion Matrix - Decision Tree')\nprint(pd.crosstab(y_test.ravel(), yhatDT.ravel(), rownames = ['True'], colnames = ['Predicted'], margins = True))\n\nprint(classification_report(yhatDT,y_test))"
        }
    ],
    "metadata": {
        "celltoolbar": "Tags",
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}